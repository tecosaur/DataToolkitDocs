var documenterSearchIndex = {"docs":
[{"location":"advising/#Data-Advising","page":"Data Advice","title":"Data Advising","text":"","category":"section"},{"location":"advising/#Advice","page":"Data Advice","title":"Advice","text":"","category":"section"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"Advice","category":"page"},{"location":"advising/#DataToolkitBase.Advice","page":"Data Advice","title":"DataToolkitBase.Advice","text":"Advice{func, context} <: Function\n\nAdvices allow for composable, highly flexible modifications of data by encapsulating a function call. They are inspired by elisp's advice system, namely the most versitile form — :around advice, and Clojure's advisors.\n\nA Advice is esentially a function wrapper, with a priority::Int attribute. The wrapped functions should be of the form:\n\n(action::Function, args...; kargs...) ->\n  ([post::Function], action::Function, args::Tuple, [kargs::NamedTuple])\n\nShort-hand return values with post or kargs omitted are also accepted, in which case default values (the identity function and (;) respectivly) will be automatically substituted in.\n\n    input=(action args kwargs)\n         ┃                 ┏╸post=identity\n       ╭─╂────advisor 1────╂─╮\n       ╰─╂─────────────────╂─╯\n       ╭─╂────advisor 2────╂─╮\n       ╰─╂─────────────────╂─╯\n       ╭─╂────advisor 3────╂─╮\n       ╰─╂─────────────────╂─╯\n         ┃                 ┃\n         ▼                 ▽\naction(args; kargs) ━━━━▶ post╺━━▶ result\n\nTo specify which transforms a Advice should be applied to, ensure you add the relevant type parameters to your transducing function. In cases where the transducing function is not applicable, the Advice will simply act as the identity function.\n\nAfter all applicable Advices have been applied, action(args...; kargs...) |> post is called to produce the final result.\n\nThe final post function is created by rightwards-composition with every post entry of the advice forms (i.e. at each stage post = post ∘ extra is run).\n\nThe overall behaviour can be thought of as shells of advice.\n\n        ╭╌ advisor 1 ╌╌╌╌╌╌╌╌─╮\n        ┆ ╭╌ advisor 2 ╌╌╌╌╌╮ ┆\n        ┆ ┆                 ┆ ┆\ninput ━━┿━┿━━━▶ function ━━━┿━┿━━▶ result\n        ┆ ╰╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╯ ┆\n        ╰╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╯\n\nConstructors\n\nAdvice(priority::Int, f::Function)\nAdvice(f::Function) # priority is set to 1\n\nExamples\n\n1. Logging every time a DataSet is loaded.\n\nloggingadvisor = Advice(\n    function(post::Function, f::typeof(load), loader::DataLoader, input, outtype)\n        @info \"Loading $(loader.data.name)\"\n        (post, f, (loader, input, outtype))\n    end)\n\n2. Automatically committing each data file write.\n\nwritecommitadvisor = Advice(\n    function(post::Function, f::typeof(write), writer::DataWriter{:filesystem}, output, info)\n        function writecommit(result)\n            run(`git add $output`)\n            run(`git commit -m \"update $output\"`)\n            result\n        end\n        (post ∘ writecommit, writefn, (output, info))\n    end)\n\n\n\n\n\n","category":"type"},{"location":"advising/#Advisement-points","page":"Data Advice","title":"Advisement points","text":"","category":"section"},{"location":"advising/#Parsing-and-serialisation-of-data-sets-and-collections","page":"Data Advice","title":"Parsing and serialisation of data sets and collections","text":"","category":"section"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"DataCollection​s, DataSet​s, and AbstractDataTransformer​s are advised at two stages during parsing:","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"When calling fromspec on the Dict representation, at the start of","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"parsing","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"At the end of the fromspec function, calling identity on the object","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"Serialisation is performed through the tospec call, which is also advised.","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"The signatures of the advised function calls are as follows:","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"fromspec(DataCollection, spec::Dict{String, Any}; path::Union{String, Nothing})::DataCollection\nidentity(collection::DataCollection)::DataCollection\ntospec(collection::DataCollection)::Dict","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"fromspec(DataSet, collection::DataCollection, name::String, spec::Dict{String, Any})::DataSet\nidentity(dataset::DataSet)::DataSet\ntospec(dataset::DataSet)::Dict","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"fromspec(ADT::Type{<:AbstractDataTransformer}, dataset::DataSet, spec::Dict{String, Any})::ADT\nidentity(adt::AbstractDataTransformer)::AbstractDataTransformer\ntospec(adt::AbstractDataTransformer)::Dict","category":"page"},{"location":"advising/#Processing-identifiers","page":"Data Advice","title":"Processing identifiers","text":"","category":"section"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"Both the parsing of an Identifier from a string, and the serialisation of an Identifier to a string are advised. Specifically, the following function calls:","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"parse(Identifier, spec::AbstractString, advised=true)\nstring(ident::Identifier)","category":"page"},{"location":"advising/#The-data-flow-arrows","page":"Data Advice","title":"The data flow arrows","text":"","category":"section"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"The reading, writing, and storage of data may all be advised. Specifically, the following function calls:","category":"page"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"load(loader::DataLoader, datahandle, as::Type)\nstorage(provider::DataStorage, as::Type; write::Bool)\nsave(writer::DataWriter, datahandle, info)","category":"page"},{"location":"advising/#Index-of-advised-calls","page":"Data Advice","title":"Index of advised calls","text":"","category":"section"},{"location":"advising/","page":"Data Advice","title":"Data Advice","text":"using Markdown\ncontent = Any[]\n\nconst AdviseRecord = NamedTuple{(:location, :parent, :invocation), Tuple{LineNumberNode, <:Union{Expr, Symbol}, Expr}}\nfunction findadvice!(acc::Vector{AdviseRecord}, expr::Expr; parent=nothing)\n    if expr.head == :macrocall && first(expr.args) == Symbol(\"@advise\")\n        !isnothing(parent) || @warn \"Macro @$(expr.args[2]) has no parent function\"\n        push!(acc, (; location=expr.args[2], parent, invocation=expr.args[end]))\n    else\n        if isnothing(parent) && expr.head == :function\n            parent = if first(expr.args) isa Expr\n                first(first(expr.args).args)\n            else\n                first(expr.args)\n            end\n        elseif isnothing(parent) && expr.head == :(=) &&\n            first(expr.args) isa Expr && first(expr.args).head == :call\n            parent = first(first(expr.args).args)\n        end\n        findadvice!.(Ref(acc), expr.args; parent)\n    end\nend\nfindadvice!(acc, ::Any; parent=nothing) = nothing\n\nalladvice = Vector{AdviseRecord}()\nfor (root, dirs, files) in walkdir(\"../../src\")\n    for file in files\n        file == \"precompile.jl\" && continue\n        @info \"Analysing $file for advise\"\n        path = joinpath(root, file)\n        expr = Meta.parseall(read(path, String); filename=path)\n        findadvice!(alladvice, expr)\n    end\nend\n\nAdvItem = NamedTuple{(:line, :parent, :invocation), Tuple{Int, Union{Expr, Symbol}, Expr}}\nadvbyfunc = Dict{Symbol, Dict{Symbol, Vector{AdvItem}}}()\natypes = first.(getfield.(getfield.(alladvice, :invocation), :args)) |> unique\nafiles = getfield.(getfield.(alladvice, :location), :file) |> unique\n\nfor atype in atypes\n    advs = filter(a -> first(a.invocation.args) == atype, alladvice)\n    advbyfunc[atype] = Dict{Symbol, Vector{AdvItem}}()\n    for (; location, parent, invocation) in advs\n        if !haskey(advbyfunc[atype], location.file)\n            advbyfunc[atype][location.file] = Vector{AdvItem}()\n        end\n        push!(advbyfunc[atype][location.file], (; line=location.line, parent, invocation))\n    end\nend\n\npush!(content, Markdown.Paragraph([\n    \"There are \", Markdown.Bold(string(length(alladvice))),\n    \" advised function calls, across \",\n    Markdown.Bold(string(length(unique(getfield.(getfield.(alladvice, :location), :file))))),\n    \" files, covering \", Markdown.Bold(string(length(advbyfunc))),\n    \" functions (automatically detected).\"]))\n\npush!(content, Markdown.Header{3}([\"Arranged by function\"]))\n\nfor fname in sort(keys(advbyfunc) |> collect)\n    instances = advbyfunc[fname]\n    nadv = sum(length, values(instances))\n    push!(content, Markdown.Header{4}([\n        Markdown.Code(String(fname)),\n        if nadv == 1\n            \" (1 instance)\"\n        else\n            \" ($nadv instances)\"\n        end]))\n    list = Markdown.List(Any[], -1, false)\n    for file in sort(keys(instances) |> collect)\n        details = instances[file]\n        sublist = Markdown.List(Any[], -1, false)\n        for (; line, parent, invocation) in details\n            push!(sublist.items, Markdown.Paragraph(\n                [\"On line \", string(line), \" \",\n                 Markdown.Code(string(invocation)),\n                 \" is advised within a \",\n                 Markdown.Code(string(parent)), \" method.\"]))\n        end\n        push!(list.items, Any[\n            Markdown.Paragraph([Markdown.Italic(last(splitpath(String(file))))]),\n            sublist])\n    end\n    push!(content, list)\nend\n\npush!(content, Markdown.Header{3}([\"Arranged by file\"]))\n\nadvbyfile = Dict{Symbol, Vector{AdvItem}}()\nfor (; location, parent, invocation) in alladvice\n    if !haskey(advbyfile, location.file)\n        advbyfile[location.file] = Vector{AdvItem}()\n    end\n    push!(advbyfile[location.file], (; line=location.line, parent, invocation))\nend\n\nfor file in sort(afiles)\n    instances = advbyfile[file]\n    push!(content, Markdown.Header{5}([\n        Markdown.Code(last(splitpath(String(file)))),\n        if length(instances) == 1\n            \" (1 instance)\"\n        else\n            \" ($(length(instances)) instances)\"\n        end]))\n    list = Markdown.List(Any[], -1, false)\n    for (; line, parent, invocation) in instances\n        push!(list.items, [Markdown.Paragraph(\n            [\"On line \", string(line), \" \",\n             Markdown.Code(string(invocation)),\n             \" is advised within a \",\n             Markdown.Code(string(parent)), \" method.\"])])\n    end\n    push!(content, list)\nend\n\nMarkdown.MD(content)","category":"page"},{"location":"datatoml/#Data.toml","page":"Data.toml","title":"Data.toml","text":"","category":"section"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"A collection of data sets may be encapsulated in a Data.toml file, the structure of which is described here.","category":"page"},{"location":"datatoml/#Overall-structure","page":"Data.toml","title":"Overall structure","text":"","category":"section"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"data_config_version=0\n\nname=\"data collection name\"\nuuid=\"a UUIDv4\"\nplugins=[\"plugin1\", \"plugin2\", ...]\n\n[config]\n# [Properties of the data collection itself]\n\n[[mydataset]]\nuuid=\"a UUIDv4\"\n# other properties...\n\n[[mydataset.TRANSFORMER]]\ndriver=\"transformer driver\"\ntype=[\"a QualifiedType\", ...]\npriority=1 # (optional)\n# other properties...\n\n[[mydataset]]\n# There may be multiple data sets by the same name,\n# but they must be uniquely identifyable by their properties\n\n[[exampledata]]\n# Another data set","category":"page"},{"location":"datatoml/#Attributes-of-the-data-collection","page":"Data.toml","title":"Attributes of the data collection","text":"","category":"section"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"There are four top-level non-table properties currently recognised.","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"data_config_version :: The (integer) version of the format. Currently 0 as this project is still in the alpha phase of development, moving towards beta.\nname :: an identifying string. Cannot contain :, and characters outside of [A-Za-z0-9_] are recommended against.\nuuid :: a UUIDv4 used to uniquely refer to the data collection, should it be renamed etc.\nplugins :: a list of plugins which should be used when working with this data collection","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"In addition to these four, a special table of the name config is recognised. This holds custom attributes of the data collection, e.g.","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"[config]\nmykey=\"value\"\n\n[config.defaults]\ndescription=\"Ooops, somebody forgot to describe this.\"\n\n[config.defaults.storage.filesystem]\npriority=2","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"Note that as a consequence of this special table, no data set may be named \"config\".","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"DataToolkitBase reserves exactly one config attribute: locked. This is used to indicate that the Data.toml file should not be modified, and to override it the attribute must be changed within the Data.toml file. By setting config.locked = true, you protecct yourself from accidental modifications to the data file.","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"This functionality is provided here rather than in DataToolkitsCommon etc. because it supported via the implementation of Base.iswritable(::DataCollection), and so downstream packages would only be able to support this by overriding this method.","category":"page"},{"location":"datatoml/#Structure-of-a-data-set","page":"Data.toml","title":"Structure of a data set","text":"","category":"section"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"[[mydataset]]\nuuid=\"a UUIDv4\"\n# other properties...\n\n[[mydataset.TRANSFORMER]]\ndriver=\"transformer driver\"\ntype=[\"a QualifiedType\", ...] # probably optional\ntype=\"a QualifiedType\" # single-value alternative form\npriority=1 # (optional)\n# other properties...","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"A data set is a top-level instance of an array of tables, with any name other than config. Data set names need not be unique, but should be able to be uniquely identified by the combination of their name and parameters.","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"Apart from data transformers, there is one recognised data property: uuid, a UUIDv4 string. Any number of additional properties may be given (so long as they do not conflict with the transformer names), they may have special behaviour based on plugins or extensions loaded, but will not be treated specially by DataToolkitBase.","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"A data set can have any number of data transformers, but at least two are needed for a functional data set. Data transformers are instances of an array of tables (like data sets), but directly under the data set table.","category":"page"},{"location":"datatoml/#Structure-of-a-data-transformer","page":"Data.toml","title":"Structure of a data transformer","text":"","category":"section"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"There are three data transformers types, with the following names:","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"storage\nloader\nwriter","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"All transformers recognise three properties:","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"driver, the transformer driver name, as a string\ntype, a single QualifiedType string, or an array of them\npriority, an integer which sets the order in which multiple transformers should be considered","category":"page"},{"location":"datatoml/","page":"Data.toml","title":"Data.toml","text":"The driver property is mandatory. type and priority can be omitted, in which case they will adopt the default values. The default type value is either determined dynamically from the available methods, or set for that particular transformer.","category":"page"},{"location":"usage/#Usage","page":"Usage","title":"Usage","text":"","category":"section"},{"location":"usage/#Identifying-a-dataset","page":"Usage","title":"Identifying a dataset","text":"","category":"section"},{"location":"usage/#Reading-datasets","page":"Usage","title":"Reading datasets","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"read","category":"page"},{"location":"usage/#Base.read","page":"Usage","title":"Base.read","text":"read(filename::AbstractString, DataCollection; writer::Union{Function, Nothing})\n\nRead the entire contents of a file as a DataCollection.\n\nThe default value of writer is self -> write(filename, self).\n\n\n\n\n\nread(io::IO, DataCollection; path::Union{String, Nothing}=nothing, mod::Module=Base.Main)\n\nRead the entirity of io, as a DataCollection.\n\n\n\n\n\nread(dataset::DataSet, as::Type)\nread(dataset::DataSet) # as default type\n\nObtain information from dataset in the form of as, with the appropriate loader and storage provider automatically determined.\n\nThis executes this component of the overall data flow:\n\n                 ╭────loader─────╮\n                 ╵               ▼\nStorage ◀────▶ Data          Information\n\nThe loader and storage provider are selected by identifying the highest priority loader that can be saisfied by a storage provider. What this looks like in practice is illustrated in the diagram below.\n\n      read(dataset, Matrix) ⟶ ::Matrix ◀╮\n         ╭───╯        ╰────────────▷┬───╯\n╔═════╸dataset╺══════════════════╗  │\n║ STORAGE      LOADERS           ║  │\n║ (⟶ File)─┬─╮ (File ⟶ String)   ║  │\n║ (⟶ IO)   ┊ ╰─(File ⟶ Matrix)─┬─╫──╯\n║ (⟶ File)┄╯   (IO ⟶ String)   ┊ ║\n║              (IO ⟶ Matrix)╌╌╌╯ ║\n╚════════════════════════════════╝\n\n  ─ the load path used\n  ┄ an option not taken\n\nTODO explain further\n\n\n\n\n\n","category":"function"},{"location":"usage/#Writing-datasets","page":"Usage","title":"Writing datasets","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"write","category":"page"},{"location":"usage/#Base.write","page":"Usage","title":"Base.write","text":"write(dataset::DataSet, info::Any)\n\nTODO write docstring\n\n\n\n\n\n","category":"function"},{"location":"usage/#Accessing-the-raw-data","page":"Usage","title":"Accessing the raw data","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"open","category":"page"},{"location":"usage/#Base.open","page":"Usage","title":"Base.open","text":"open(dataset::DataSet, as::Type; write::Bool=false)\n\nObtain the data of dataset in the form of as, with the appropriate storage provider automatically selected.\n\nA write flag is also provided, to help the driver pick a more appropriate form of as.\n\nThis executes this component of the overall data flow:\n\n                 ╭────loader─────╮\n                 ╵               ▼\nStorage ◀────▶ Data          Information\n\n\n\n\n\n","category":"function"},{"location":"errors/#Errors","page":"Errors","title":"Errors","text":"","category":"section"},{"location":"errors/","page":"Errors","title":"Errors","text":"This package tries to minimise the use of generic errors, and maximise the helpfulness of error messages. To that end, a number of new error types are defined.","category":"page"},{"location":"errors/#Identifier-exceptions","page":"Errors","title":"Identifier exceptions","text":"","category":"section"},{"location":"errors/","page":"Errors","title":"Errors","text":"UnresolveableIdentifier","category":"page"},{"location":"errors/#DataToolkitBase.UnresolveableIdentifier","page":"Errors","title":"DataToolkitBase.UnresolveableIdentifier","text":"UnresolveableIdentifier{T}(identifier::Union{String, UUID}, [collection::DataCollection])\n\nNo T (opionally from collection) could be found that matches identifier.\n\nExample occurances\n\njulia> d\"iirs\"\nERROR: UnresolveableIdentifier: \"iirs\" does not match any availible data sets\n  Did you perhaps mean to refer to one of these data sets?\n    ■:iris (75% match)\nStacktrace: [...]\n\njulia> d\"iris::Int\"\nERROR: UnresolveableIdentifier: \"iris::Int\" does not match any availible data sets\n  Without the type restriction, however, the following data sets match:\n    datatest:iris, which is availible as a DataFrame, Matrix, CSV.File\nStacktrace: [...]\n\n\n\n\n\n","category":"type"},{"location":"errors/","page":"Errors","title":"Errors","text":"AmbiguousIdentifier","category":"page"},{"location":"errors/#DataToolkitBase.AmbiguousIdentifier","page":"Errors","title":"DataToolkitBase.AmbiguousIdentifier","text":"AmbiguousIdentifier(identifier::Union{String, UUID}, matches::Vector, [collection])\n\nSearching for identifier (optionally within collection), found multiple matches (provided as matches).\n\nExample occurance\n\njulia> d\"multimatch\"\nERROR: AmbiguousIdentifier: \"multimatch\" matches multiple data sets\n    ■:multimatch [45685f5f-e6ff-4418-aaf6-084b847236a8]\n    ■:multimatch [92be4bda-55e9-4317-aff4-8d52ee6a5f2c]\nStacktrace: [...]\n\n\n\n\n\n","category":"type"},{"location":"errors/#Package-exceptions","page":"Errors","title":"Package exceptions","text":"","category":"section"},{"location":"errors/","page":"Errors","title":"Errors","text":"UnregisteredPackage","category":"page"},{"location":"errors/#DataToolkitBase.UnregisteredPackage","page":"Errors","title":"DataToolkitBase.UnregisteredPackage","text":"UnregisteredPackage(pkg::Symbol, mod::Module)\n\nThe package pkg was asked for within mod, but has not been registered by mod, and so cannot be loaded.\n\nExample occurance\n\njulia> @import Foo\nERROR: UnregisteredPackage: Foo has not been registered by Main, see @addpkg for more information\nStacktrace: [...]\n\n\n\n\n\n","category":"type"},{"location":"errors/","page":"Errors","title":"Errors","text":"MissingPackage","category":"page"},{"location":"errors/#DataToolkitBase.MissingPackage","page":"Errors","title":"DataToolkitBase.MissingPackage","text":"MissingPackage(pkg::Base.PkgId)\n\nThe package pkg was asked for, but does not seem to be availible in the current environment.\n\nExample occurance\n\njulia> @addpkg Bar \"00000000-0000-0000-0000-000000000000\"\nBar [00000000-0000-0000-0000-000000000000]\n\njulia> @import Bar\n[ Info: Lazy-loading Bar [00000000-0000-0000-0000-000000000001]\nERROR: MissingPackage: Bar [00000000-0000-0000-0000-000000000001] has been required, but does not seem to be installed.\nStacktrace: [...]\n\n\n\n\n\n","category":"type"},{"location":"errors/#Data-Operation-exceptions","page":"Errors","title":"Data Operation exceptions","text":"","category":"section"},{"location":"errors/","page":"Errors","title":"Errors","text":"CollectionVersionMismatch","category":"page"},{"location":"errors/#DataToolkitBase.CollectionVersionMismatch","page":"Errors","title":"DataToolkitBase.CollectionVersionMismatch","text":"CollectionVersionMismatch(version::Int)\n\nThe version of the collection currently being acted on is not supported by the current version of DataToolkitBase.\n\nExample occurance\n\njulia> fromspec(DataCollection, SmallDict{String, Any}(\"data_config_version\" => -1))\nERROR: CollectionVersionMismatch: -1 (specified) ≠ 0 (current)\n  The data collection specification uses the v-1 data collection format, however\n  the installed DataToolkitBase version expects the v0 version of the format.\n  In the future, conversion facilities may be implemented, for now though you\n  will need to manually upgrade the file to the v0 format.\nStacktrace: [...]\n\n\n\n\n\n","category":"type"},{"location":"errors/","page":"Errors","title":"Errors","text":"EmptyStackError","category":"page"},{"location":"errors/#DataToolkitBase.EmptyStackError","page":"Errors","title":"DataToolkitBase.EmptyStackError","text":"EmptyStackError()\n\nAn attempt was made to perform an operation on a collection within the data stack, but the data stack is empty.\n\nExample occurance\n\njulia> getlayer(nothing) # with an empty STACK\nERROR: EmptyStackError: The data collection stack is empty\nStacktrace: [...]\n\n\n\n\n\n","category":"type"},{"location":"errors/","page":"Errors","title":"Errors","text":"ReadonlyCollection","category":"page"},{"location":"errors/#DataToolkitBase.ReadonlyCollection","page":"Errors","title":"DataToolkitBase.ReadonlyCollection","text":"ReadonlyCollection(collection::DataCollection)\n\nModification of collection is not viable, as it is read-only.\n\nExample Occurance\n\njulia> lockedcollection = DataCollection(SmallDict{String, Any}(\"uuid\" => Base.UUID(rand(UInt128)), \"config\" => SmallDict{String, Any}(\"locked\" => true)))\njulia> write(lockedcollection)\nERROR: ReadonlyCollection: The data collection unnamed#298 is locked\nStacktrace: [...]\n\n\n\n\n\n","category":"type"},{"location":"errors/","page":"Errors","title":"Errors","text":"TransformerError","category":"page"},{"location":"errors/#DataToolkitBase.TransformerError","page":"Errors","title":"DataToolkitBase.TransformerError","text":"TransformerError(msg::String)\n\nA catch-all for issues involving data transformers, with details given in msg.\n\nExample occurance\n\njulia> emptydata = DataSet(DataCollection(), \"empty\", SmallDict{String, Any}(\"uuid\" => Base.UUID(rand(UInt128))))\nDataSet empty\n\njulia> read(emptydata)\nERROR: TransformerError: Data set \"empty\" could not be loaded in any form.\nStacktrace: [...]\n\n\n\n\n\n","category":"type"},{"location":"errors/","page":"Errors","title":"Errors","text":"UnsatisfyableTransformer","category":"page"},{"location":"errors/#DataToolkitBase.UnsatisfyableTransformer","page":"Errors","title":"DataToolkitBase.UnsatisfyableTransformer","text":"UnsatisfyableTransformer{T}(dataset::DataSet, types::Vector{QualifiedType})\n\nA transformer (of type T) that could provide any of types was asked for, but there is no transformer that satisfies this restriction.\n\nExample occurance\n\njulia> emptydata = DataSet(DataCollection(), \"empty\", SmallDict{String, Any}(\"uuid\" => Base.UUID(rand(UInt128))))\nDataSet empty\n\njulia> read(emptydata, String)\nERROR: UnsatisfyableTransformer: There are no loaders for \"empty\" that can provide a String. The defined loaders are as follows:\nStacktrace: [...]\n\n\n\n\n\n","category":"type"},{"location":"errors/","page":"Errors","title":"Errors","text":"OrphanDataSet","category":"page"},{"location":"errors/#DataToolkitBase.OrphanDataSet","page":"Errors","title":"DataToolkitBase.OrphanDataSet","text":"OrphanDataSet(dataset::DataSet)\n\nThe data set (dataset) is no longer a child of its parent collection.\n\nThis error should not occur, and is intended as a sanity check should something go quite wrong.\n\n\n\n\n\n","category":"type"},{"location":"newtransformer/#Creating-a-new-data-transformer","page":"Transformer backends","title":"Creating a new data transformer","text":"","category":"section"},{"location":"newtransformer/","page":"Transformer backends","title":"Transformer backends","text":"As mentioned before, there are three types of data transformer:","category":"page"},{"location":"newtransformer/","page":"Transformer backends","title":"Transformer backends","text":"storage\nloader\nwriter","category":"page"},{"location":"newtransformer/","page":"Transformer backends","title":"Transformer backends","text":"The three corresponding Julia types are:","category":"page"},{"location":"newtransformer/","page":"Transformer backends","title":"Transformer backends","text":"DataStorage\nDataLoader\nDataWriter","category":"page"},{"location":"newtransformer/","page":"Transformer backends","title":"Transformer backends","text":"All three types accept a driver (symbol) type parameter. For example, a storage transformer using a \"filesystem\" driver would be of the type DataStorage{:filesystem}.","category":"page"},{"location":"newtransformer/","page":"Transformer backends","title":"Transformer backends","text":"Adding support for a new driver is a simple as adding method implementations for the three key data transformer methods:","category":"page"},{"location":"newtransformer/","page":"Transformer backends","title":"Transformer backends","text":"load","category":"page"},{"location":"newtransformer/#DataToolkitBase.load","page":"Transformer backends","title":"DataToolkitBase.load","text":"load(loader::DataLoader{driver}, source::Any, as::Type)\n\nUsing a certain loader, obtain information in the form of as from the data given by source.\n\nThis fufills this component of the overall data flow:\n\n  ╭────loader─────╮\n  ╵               ▼\nData          Information\n\nWhen the loader produces nothing this is taken to indicate that it was unable to load the data for some reason, and that another loader should be tried if possible. This can be considered a soft failiure. Any other value is considered valid information.\n\n\n\n\n\n","category":"function"},{"location":"newtransformer/","page":"Transformer backends","title":"Transformer backends","text":"storage","category":"page"},{"location":"newtransformer/","page":"Transformer backends","title":"Transformer backends","text":"save","category":"page"},{"location":"newtransformer/#DataToolkitBase.save","page":"Transformer backends","title":"DataToolkitBase.save","text":"save(writer::Datasaveer{driver}, destination::Any, information::Any)\n\nUsing a certain writer, save the information to the destination.\n\nThis fufills this component of the overall data flow:\n\nData          Information\n  ▲               ╷\n  ╰────writer─────╯\n\n\n\n\n\n","category":"function"},{"location":"libinternal/#Private-API","page":"Internals","title":"Private API","text":"","category":"section"},{"location":"libinternal/#Abstract-Data-Transformer","page":"Internals","title":"Abstract Data Transformer","text":"","category":"section"},{"location":"libinternal/","page":"Internals","title":"Internals","text":"AbstractDataTransformer","category":"page"},{"location":"libinternal/#DataToolkitBase.AbstractDataTransformer","page":"Internals","title":"DataToolkitBase.AbstractDataTransformer","text":"The supertype for methods producing or consuming data.\n\n                 ╭────loader─────╮\n                 ╵               ▼\nStorage ◀────▶ Data          Information\n                 ▲               ╷\n                 ╰────writer─────╯\n\nThere are three subtypes:\n\nDataStorage\nDataLoader\nDataWrite\n\nEach subtype takes a Symbol type parameter designating the driver which should be used to perform the data operation. In addition, each subtype has the following fields:\n\ndataset::DataSet, the data set the method operates on\ntype::Vector{<:QualifiedType}, the Julia types the method supports\npriority::Int, the priority with which this method should be used, compared to alternatives. Lower values have higher priority.\nparameters::SmallDict{String, Any}, any parameters applied to the method.\n\n\n\n\n\n","category":"type"},{"location":"libinternal/#Advice-Amalgamation","page":"Internals","title":"Advice Amalgamation","text":"","category":"section"},{"location":"libinternal/","page":"Internals","title":"Internals","text":"AdviceAmalgamation","category":"page"},{"location":"libinternal/#DataToolkitBase.AdviceAmalgamation","page":"Internals","title":"DataToolkitBase.AdviceAmalgamation","text":"A collection of Advices sourced from availible Plugins.\n\nLike individual Advices, a AdviceAmalgamation can be called as a function. However, it also supports the following convenience syntax:\n\n(::AdviceAmalgamation)(f::Function, args...; kargs...) # -> result\n\nConstructors\n\nAdviceAmalgamation(adviseall::Function, advisors::Vector{Advice},\n                   plugins_wanted::Vector{String}, plugins_used::Vector{String})\nAdviceAmalgamation(plugins::Vector{String})\nAdviceAmalgamation(collection::DataCollection)\n\n\n\n\n\n","category":"type"},{"location":"libinternal/#Qualified-Types","page":"Internals","title":"Qualified Types","text":"","category":"section"},{"location":"libinternal/","page":"Internals","title":"Internals","text":"QualifiedType","category":"page"},{"location":"libinternal/#DataToolkitBase.QualifiedType","page":"Internals","title":"DataToolkitBase.QualifiedType","text":"A representation of a Julia type that does not need the type to be defined in the Julia session, and can be stored as a string. This is done by storing the type name and the module it belongs to as Symbols.\n\nwarning: Warning\nWhile QualifiedType is currently quite capable, it is not currently able to express the full gamut of Julia types. In future this will be improved, but it will likely always be restricted to a certain subset.\n\nSubtyping\n\nWhile the subtype operator cannot work on QualifiedTypes (<: is a built-in), when the Julia types are defined the subset operator ⊆ can be used instead. This works by simply converting the QualifiedTypes to the correspanding Type and then applying the subtype operator.\n\njulia> QualifiedTypes(:Base, :Vector) ⊆ QualifiedTypes(:Core, :Array)\ntrue\n\njulia> Matrix ⊆ QualifiedTypes(:Core, :Array)\ntrue\n\njulia> QualifiedTypes(:Base, :Vector) ⊆ AbstractVector\ntrue\n\njulia> QualifiedTypes(:Base, :Foobar) ⊆ AbstractVector\nfalse\n\nConstructors\n\nQualifiedType(parentmodule::Symbol, typename::Symbol)\nQualifiedType(t::Type)\n\nParsing\n\nA QualifiedType can be expressed as a string as \"$parentmodule.$typename\". This can be easily parsed as a QualifiedType, e.g. parse(QualifiedType, \"Core.IO\").\n\n\n\n\n\n","category":"type"},{"location":"libinternal/#Global-variables","page":"Internals","title":"Global variables","text":"","category":"section"},{"location":"libinternal/","page":"Internals","title":"Internals","text":"STACK","category":"page"},{"location":"libinternal/#DataToolkitBase.STACK","page":"Internals","title":"DataToolkitBase.STACK","text":"The set of data collections currently availible.\n\n\n\n\n\n","category":"constant"},{"location":"libinternal/","page":"Internals","title":"Internals","text":"PLUGINS","category":"page"},{"location":"libinternal/#DataToolkitBase.PLUGINS","page":"Internals","title":"DataToolkitBase.PLUGINS","text":"The set of plugins currently availible.\n\n\n\n\n\n","category":"constant"},{"location":"libinternal/","page":"Internals","title":"Internals","text":"DataToolkitBase.EXTRA_PACKAGES","category":"page"},{"location":"libinternal/#DataToolkitBase.EXTRA_PACKAGES","page":"Internals","title":"DataToolkitBase.EXTRA_PACKAGES","text":"The set of packages loaded by each module via @addpkg, for import with @import.\n\nMore specifically, when a module M invokes @addpkg pkg id then EXTRA_PACKAGES[M][pkg] = id is set, and then this information is used with @import to obtain the package from the root module.\n\n\n\n\n\n","category":"constant"},{"location":"libinternal/","page":"Internals","title":"Internals","text":"DATA_CONFIG_RESERVED_ATTRIBUTES","category":"page"},{"location":"libinternal/#DataToolkitBase.DATA_CONFIG_RESERVED_ATTRIBUTES","page":"Internals","title":"DataToolkitBase.DATA_CONFIG_RESERVED_ATTRIBUTES","text":"The data specification TOML format constructs a DataCollection, which itself contains DataSets, comprised of metadata and AbstractDataTransformers.\n\nDataCollection\n├─ DataSet\n│  ├─ AbstractDataTransformer\n│  └─ AbstractDataTransformer\n├─ DataSet\n⋮\n\nWithin each scope, there are certain reserved attributes. They are listed in this Dict under the following keys:\n\n:collection for DataCollection\n:dataset for DataSet\n:transformer for AbstractDataTransformer\n\n\n\n\n\n","category":"constant"},{"location":"repl/#The-Data-REPL","page":"REPL","title":"The Data REPL","text":"","category":"section"},{"location":"repl/#General-design","page":"REPL","title":"General design","text":"","category":"section"},{"location":"repl/","page":"REPL","title":"REPL","text":"An extensible \"Data REPL\" is provided to make directly interacting with the Data.toml a bit more convenient. It can be entered by pressing } on an empty julia> REPL line.","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"julia> # type }\ndata>\ndata> help\n Command  Action\n ───────────────────────────────────────────────────────────\n help     Display help information on the available commands","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"The foremost data collection is also listed in the prompt in much the same manner as (environment) pkg>, i.e.","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"(⋅) data>        # No currently loaded data collections\n(example) data>  # The top data collection is \"example\"","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"Commands (and sub-commands) can be triggered by typing them out in full (i.e. cmd args...) but also abbreviated up to the unique stem. For instance if cmd is the only command starting with c, then it can be called with any of","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"data> cmd args...\ndata> cm args...\ndata> c args...","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"However, should a command conflict also exist, then c is no longer a unique stem and so c args... will produce an error message like so:","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"data> c args...\n ! Multiple matching Data REPL commands: cmd, conflict","category":"page"},{"location":"repl/#The-help-command","page":"REPL","title":"The help command","text":"","category":"section"},{"location":"repl/","page":"REPL","title":"REPL","text":"help is implemented specially in the Data REPL. It can be invoked normally (i.e. help cmd) but also with ? prefix (i.e. ?cmd). Furthermore, all commands with sub-commands with automatically have a help sub-command added. Overall, help supports the following usage patterns.","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"data> help             # List available commands.\ndata> help cmd         # Obtain the help for cmd, or\ndata> help cmd         # list available sub-command (if applicable).\ndata> ?cmd             # Obtain the help for cmd.\ndata> help cmd subcmd  # Obtain the help for subcmd.\ndata> ?cmd subcmd      # Obtain the help for subcmd.\ndata> cmd help subcmd  # Obtain the help for subcmd.\ndata> cmd ?subcmd      # Obtain the help for subcmd.","category":"page"},{"location":"repl/#Extending-the-Data-REPL","page":"REPL","title":"Extending the Data REPL","text":"","category":"section"},{"location":"repl/#Registering-commands","page":"REPL","title":"Registering commands","text":"","category":"section"},{"location":"repl/","page":"REPL","title":"REPL","text":"To register a command, one simply needs to push a ReplCmd onto REPL_CMDS.","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"REPL_CMDS","category":"page"},{"location":"repl/#DataToolkitBase.REPL_CMDS","page":"REPL","title":"DataToolkitBase.REPL_CMDS","text":"The set of commands availible directly in the Data REPL.\n\n\n\n\n\n","category":"constant"},{"location":"repl/","page":"REPL","title":"REPL","text":"ReplCmd","category":"page"},{"location":"repl/#DataToolkitBase.ReplCmd","page":"REPL","title":"DataToolkitBase.ReplCmd","text":"A command that can be used in the Data REPL (accessible through '}').\n\nA ReplCmd must have a:\n\nname, a symbol designating the command keyword.\ntrigger, a string used as the command trigger (defaults to String(name)).\ndescription, a short overview of the functionality as a string or displayable object.\nexecute, either a list of sub-ReplCmds, or a function which will perform the command's action. The function must take a single argument, the rest of the command as an AbstractString (for example, 'cmd arg1 arg2' will call the execute function with \"arg1 arg2\").\n\nConstructors\n\nReplCmd{name::Symbol}(trigger::String, description::Any, execute::Function)\nReplCmd{name::Symbol}(description::Any, execute::Function)\nReplCmd(name::Union{Symbol, String}, trigger::String, description::Any, execute::Function)\nReplCmd(name::Union{Symbol, String}, description::Any, execute::Function)\n\nExamples\n\nReplCmd(:echo, \"print the argument\", identity)\nReplCmd(:addone, \"return the input plus one\", v -> 1 + parse(Int, v))\nReplCmd(:math, \"A collection of basic integer arithmatic\",\n    [ReplCmd(:add, \"a + b + ...\", nums -> sum(parse.(Int, split(nums))))],\n     ReplCmd(:mul, \"a * b * ...\", nums -> prod(parse.(Int, split(nums)))))\n\nMethods\n\nhelp(::ReplCmd) # -> print detailed help\nallcompletions(::ReplCmd) # -> list all candidates\ncompletions(::ReplCmd, sofar::AbstractString) # -> list relevant candidates\n\n\n\n\n\n","category":"type"},{"location":"repl/#Completion","page":"REPL","title":"Completion","text":"","category":"section"},{"location":"repl/","page":"REPL","title":"REPL","text":"As hinted by the ReplCmd docstring, completions can be implemented by implementing completions(::ReplCmd{:CMD_ID}, sofar::AbstractString) or allcompletions.","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"completions","category":"page"},{"location":"repl/#DataToolkitBase.completions","page":"REPL","title":"DataToolkitBase.completions","text":"completions(r::ReplCmd, sofar::AbstractString)\n\nObtain a list of String completion candidates baesd on sofar. All candidates should begin with sofar.\n\nShould this function not be implemented for the specific ReplCmd r, allcompletions(r) will be called and filter to candiadates that begin with sofar.\n\nIf r has subcommands, then the subcommand prefix will be removed and completions re-called on the relevant subcommand.\n\n\n\n\n\n","category":"function"},{"location":"repl/","page":"REPL","title":"REPL","text":"allcompletions","category":"page"},{"location":"repl/#DataToolkitBase.allcompletions","page":"REPL","title":"DataToolkitBase.allcompletions","text":"allcompletions(r::ReplCmd)\n\nObtain all possible String completion candiadates for r. This defaults to the empty vector String[].\n\nallcompletions is only called when completions(r, sofar::AbstractString) is not implemented.\n\n\n\n\n\n","category":"function"},{"location":"repl/#Helper-functions","page":"REPL","title":"Helper functions","text":"","category":"section"},{"location":"repl/","page":"REPL","title":"REPL","text":"To create a pleasant user interface, a number of utility functions are provided.","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"prompt","category":"page"},{"location":"repl/#DataToolkitBase.prompt","page":"REPL","title":"DataToolkitBase.prompt","text":"prompt(question::AbstractString, default::AbstractString=\"\",\n       allowempty::Bool=false, cleardefault::Bool=true,\n       multiline::Bool=false)\n\nInteractively ask question and return the response string, optionally with a default value. If multiline is true, RET must be pressed twice consecutively to submit a value.\n\nUnless allowempty is set an empty response is not accepted. If cleardefault is set, then an initial backspace will clear the default value.\n\nThe prompt supports the following line-edit-y keys:\n\nleft arrow\nright arrow\nhome\nend\ndelete forwards\ndelete backwards\n\nExample\n\njulia> prompt(\"What colour is the sky? \")\nWhat colour is the sky? Blue\n\"Blue\"\n\n\n\n\n\n","category":"function"},{"location":"repl/","page":"REPL","title":"REPL","text":"prompt_char","category":"page"},{"location":"repl/#DataToolkitBase.prompt_char","page":"REPL","title":"DataToolkitBase.prompt_char","text":"prompt_char(question::AbstractString, options::Vector{Char},\n            default::Union{Char, Nothing}=nothing)\n\nInteratively ask question, only accepting options keys as answers. All keys are converted to lower case on input. If default is not nothing and 'RET' is hit, then default will be returned.\n\nShould '^C' be pressed, an InterruptException will be thrown.\n\n\n\n\n\n","category":"function"},{"location":"repl/","page":"REPL","title":"REPL","text":"confirm_yn","category":"page"},{"location":"repl/#DataToolkitBase.confirm_yn","page":"REPL","title":"DataToolkitBase.confirm_yn","text":"confirm_yn(question::AbstractString, default::Bool=false)\n\nInteractively ask question and accept y/Y/n/N as the response. If any other key is pressed, then default will be taken as the response. A \" [y/n]: \" string will be appended to the question, with y/n capitalised to indicate the default value.\n\nExample\n\njulia> confirm_yn(\"Do you like chocolate?\", true)\nDo you like chocolate? [Y/n]: y\ntrue\n\n\n\n\n\n","category":"function"},{"location":"repl/","page":"REPL","title":"REPL","text":"peelword","category":"page"},{"location":"repl/#DataToolkitBase.peelword","page":"REPL","title":"DataToolkitBase.peelword","text":"peelword(input::AbstractString)\n\nRead the next 'word' from input. If input starts with a quote, this is the unescaped text between the opening and closing quote. Other wise this is simply the next word.\n\nReturns a tuple of the form (word, rest).\n\nExample\n\njulia> peelword(\"one two\")\n(\"one\", \"two\")\n\njulia> peelword(\"\"one two\" three\")\n(\"one two\", \"three\")\n\n\n\n\n\n","category":"function"},{"location":"repl/#Simple-example","page":"REPL","title":"Simple example","text":"","category":"section"},{"location":"repl/","page":"REPL","title":"REPL","text":"In the below example we will extend the Data REPL by adding a command cowsay which simply call the (assumed to be installed) system cowsay executable.","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"function cowsay_repl(input::AbstractString)\n    if isempty(input)\n        confirm_yn(\"Are you ready to hear your fortune?\", true) &&\n            cowsay_repl(read(`fortune`, String))\n    else\n        println(read(`cowsay $input`, String))\n    end\nend\n\npush!(REPL_CMDS, ReplCmd(:cowsay3,\n                         \"Hear what the cow has to say\n\\n Call with no argument to obtain a fortune.\",\n                         cowsay_repl))\n\nDataToolkitBase.allcompletions(::ReplCmd{:cowsay}) =\n    [\"Improve your data management with DataToolkits & co.\"]","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"If you enter the Data REPL, you will be able to note that:","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"cowsay is listed in data> help\nrunning cowsay with no arguments results in a Y/n prompt to show a fortune\npressing TAB after cowsay fills in the sole completion, Improve your data   management with DataToolkits & co..","category":"page"},{"location":"repl/","page":"REPL","title":"REPL","text":"(⋅) data> help\n Command  Action\n ───────────────────────────────────────────────────────────\n cowsay   Hear what the cow has to say\n help     Display help information on the available commands\n\n(⋅) data> ?cowsay3\n Hear what the cow has to say\n\n Call with no argument to obtain a fortune.\n\n(⋅) data> cowsay\nAre you ready to hear your fortune? [Y/n]: y\n _________________________________________\n/ (1) A sheet of paper is an ink-lined    \\\n| plane. (2) An inclined plane is a slope |\n| up. (3) A slow pup is a lazy dog.       |\n|                                         |\n| QED: A sheet of paper is a lazy dog.    |\n|                                         |\n| -- Willard Espy, \"An Almanac of Words   |\n\\ at Play\"                                /\n -----------------------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n","category":"page"},{"location":"packages/#Using-Packages","page":"Packages","title":"Using Packages","text":"","category":"section"},{"location":"packages/","page":"Packages","title":"Packages","text":"It is entirely likely that in the course of writing a package providing a custom data transformer, one would come across packages that may be needed.","category":"page"},{"location":"packages/","page":"Packages","title":"Packages","text":"Every possibly desired package could be shoved into the list of dependences, but this is a somewhat crude approach. A more granular approach is enabled with two macros, @addpkg and @import.","category":"page"},{"location":"packages/#Letting-DataToolkitBase-know-about-extra-packages","page":"Packages","title":"Letting DataToolkitBase know about extra packages","text":"","category":"section"},{"location":"packages/","page":"Packages","title":"Packages","text":"@addpkg","category":"page"},{"location":"packages/#DataToolkitBase.@addpkg","page":"Packages","title":"DataToolkitBase.@addpkg","text":"@addpkg name::Symbol uuid::String\n\nRegister the package identifed by name with UUID uuid. This package may now be used with @import $name.\n\nAll @addpkg statements should lie within a module's __init__ function.\n\nExample\n\n@addpkg CSV \"336ed68f-0bac-5ca0-87d4-7b16caf5d00b\"\n\n\n\n\n\n","category":"macro"},{"location":"packages/#Using-extra-packages","page":"Packages","title":"Using extra packages","text":"","category":"section"},{"location":"packages/","page":"Packages","title":"Packages","text":"@import","category":"page"},{"location":"packages/#DataToolkitBase.@import","page":"Packages","title":"DataToolkitBase.@import","text":"@import pkg1, pkg2...\n@import pkg1 as name1, pkg2 as name2...\n@import pkg: foo, bar...\n@import pkg: foo as bar, bar as baz...\n\nFetch modules previously registered with @addpkg, and import them into the current namespace. This macro tries to largely mirror the syntax of using.\n\nIf a required package had to be loaded for the @import statement, a PkgRequiredRerunNeeded singleton will be returned.\n\nExample\n\n@import pkg\npkg.dothing(...)\n# Alternative form\n@import pkg: dothing\ndothing(...)\n\n\n\n\n\n","category":"macro"},{"location":"packages/#Example","page":"Packages","title":"Example","text":"","category":"section"},{"location":"packages/","page":"Packages","title":"Packages","text":"module DataToolkitExample\n\nusing DataToolkitBase\nusing DataFrame\n\nfunction __init__()\n    @addpkg CSV \"336ed68f-0bac-5ca0-87d4-7b16caf5d00b\"\n    @addpkg DelimitedFiles \"8bb1440f-4735-579b-a4ab-409b98df4dab\"\nend\n\nfunction load(::DataLoader{:csv}, from::IOStream, ::Type{DataFrame})\n    @import CSV\n    result = CSV.read(from, DataFrame)\n    close(from)\n    result\nend\n\nfunction load(::DataLoader{:delimcsv}, from::IOStream, ::Type{DataFrame})\n    @import DelimitedFiles\n    result = DelimitedFiles.readdlm(from, ',', DataFrame)\n    close(from)\n    result\nend\n\nend","category":"page"},{"location":"#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"#The-problem-with-the-current-state-of-affairs","page":"Introduction","title":"The problem with the current state of affairs","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Data is beguiling. It can initially seem simple to deal with: \"here I have a file, and that's it\". However as soon as you do things with the data you're prone to be asked tricky questions like:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"where's the data?\nhow did you process that data?\nhow can I be sure I'm looking at the same data as you?","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"This is no small part of the replication crisis.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: image)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Further concerns arise as soon as you start dealing with large quantities of data, or computationally expensive derived data sets. For example:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Have I already computed this data set somewhere else?\nIs my generated data up to date with its sources/dependencies?","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Generic tools exist for many parts of this problem, but there are some benefits that can be realised by creating a Julia-specific system, namely:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Having all pertinent environmental information in the data processing contained in a single Project.toml\nImproved convenience in data loading and management, compared to a generic solution\nAllowing datasets to be easily shared with a Julia package","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"In addition, the Julia community seems to have a strong tendency to NIH[NIH] tools, so we may as well get ahead of this and try to make something good 😛.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"[NIH]: Not Invented Here, a tendency to \"reinvent the wheel\" to avoid using tools from external origins &mdash; it would of course be better if you (re)made it.","category":"page"},{"location":"#Pre-existing-solutions","page":"Introduction","title":"Pre-existing solutions","text":"","category":"section"},{"location":"#DataLad","page":"Introduction","title":"DataLad","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Does a lot of things well\nPuts information on how to create data in git commit messages (bad)\nNo data file specification","category":"page"},{"location":"#Kedro-data-catalog","page":"Introduction","title":"Kedro data catalog","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Has a file defining all the data (good)\nHas poor versioning\nhttps://kedro.readthedocs.io/en/stable/data/data_catalog.html\nData Catalog CLI","category":"page"},{"location":"#Snakemake","page":"Introduction","title":"Snakemake","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Workflow manager, with remote file support\nSnakemake Remote Files\nGood list of possible file locations to handle\nDrawback is that you have to specify the location you expect(S3, http, FTP, etc.)\nNo data file specification","category":"page"},{"location":"#Nextflow","page":"Introduction","title":"Nextflow","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Workflow manager, with remote file support\nDocs on files and IO\nDocs on S3\nYou just call file() and nextflow figures out under the hood the protocol whether it should pull it from S3, http, FTP, or a local file.\nNo data file specification","category":"page"}]
}
